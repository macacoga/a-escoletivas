# Ferramenta de AnÃ¡lise de AÃ§Ãµes Coletivas

Uma ferramenta profissional para automatizar a coleta, processamento e visualizaÃ§Ã£o de dados de aÃ§Ãµes coletivas judiciais, com foco em execuÃ§Ãµes individuais pÃ³s-conhecimento.

## ğŸ¯ Objetivo

Automatizar o processo de anÃ¡lise de aÃ§Ãµes coletivas judiciais, permitindo:
- Coleta automÃ¡tica de dados do sistema FalcÃ£o
- Processamento de linguagem natural para extrair insights
- Armazenamento estruturado em banco de dados
- VisualizaÃ§Ã£o e anÃ¡lise de dados

## ğŸ—ï¸ Arquitetura

```
src/acoes_coletivas/
â”œâ”€â”€ core/           # Funcionalidades principais
â”œâ”€â”€ scraper/        # MÃ³dulos de extraÃ§Ã£o de dados
â”œâ”€â”€ database/       # Gerenciamento de dados
â”œâ”€â”€ nlp/           # Processamento de linguagem natural
â”œâ”€â”€ config/        # ConfiguraÃ§Ãµes do sistema
â””â”€â”€ utils/         # UtilitÃ¡rios diversos
```

## ğŸš€ Funcionalidades

### Fase 1: Coleta e Armazenamento âœ…
- [x] ConfiguraÃ§Ã£o profissional do ambiente
- [x] MÃ³dulo de coleta via Selenium e requests
- [x] Banco de dados SQLite estruturado
- [x] Sistema de logging avanÃ§ado
- [x] ConfiguraÃ§Ã£o centralizada
- [x] Tratamento de erros robusto

### Fase 2: Processamento NLP (Em desenvolvimento)
- [ ] SumarizaÃ§Ã£o automÃ¡tica de textos
- [ ] ExtraÃ§Ã£o de palavras-chave
- [ ] ClassificaÃ§Ã£o de temas
- [ ] AnÃ¡lise de sentimentos
- [ ] IdentificaÃ§Ã£o de entidades nomeadas

### Fase 3: Interface e VisualizaÃ§Ã£o (Planejado)
- [ ] Interface web com Flask
- [ ] Dashboard interativo
- [ ] RelatÃ³rios automatizados
- [ ] ExportaÃ§Ã£o de dados
- [ ] API REST

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- Chrome ou Firefox (para Selenium)
- Pelo menos 2GB de espaÃ§o em disco
- ConexÃ£o com internet

## ğŸ”§ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <repository-url>
cd a-escoletivas
```

2. **Crie um ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

4. **Configure o ambiente:**
```bash
cp .env.example .env
# Edite o arquivo .env com suas configuraÃ§Ãµes
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Principais configuraÃ§Ãµes no arquivo `.env`:

```env
# ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
APP_NAME="Ferramenta de AnÃ¡lise de AÃ§Ãµes Coletivas"
DEBUG=false

# ConfiguraÃ§Ãµes do banco de dados
DATABASE_URL="sqlite:///./data/acoes_coletivas.db"

# ConfiguraÃ§Ãµes do scraper
SELENIUM_TIMEOUT=30
REQUEST_DELAY=2.0
SELENIUM_HEADLESS=true

# ConfiguraÃ§Ãµes de busca
DEFAULT_DEFENDANT="Banco do Brasil"
DEFAULT_COLLECTIONS=["acordaos", "sentencas"]
```

### ConfiguraÃ§Ã£o do WebDriver

Para uso com Chrome:
```bash
# Instale o ChromeDriver
wget https://chromedriver.storage.googleapis.com/LATEST_RELEASE
# Adicione ao PATH ou configure no cÃ³digo
```

## ğŸ® Uso

### Estrutura de Dados

O sistema trabalha com trÃªs principais entidades:

1. **ProcessoJudicial**: Dados dos processos coletados
2. **ResultadoNLP**: Resultados do processamento de linguagem natural
3. **LogExecucao**: Logs de operaÃ§Ãµes do sistema

### Exemplo de Uso BÃ¡sico

```python
from src.acoes_coletivas.database.manager import DatabaseManager
from src.acoes_coletivas.scraper.base import BaseScraper
from src.acoes_coletivas.config.settings import settings

# Inicializar o banco de dados
db = DatabaseManager()

# Verificar estatÃ­sticas
stats = db.get_stats()
print(f"Total de processos: {stats['total_processos']}")
print(f"Processos processados: {stats['processos_processados']}")
```

### Coleta de Dados

```python
# Exemplo de coleta manual
scraper = SeleniumScraper()  # Implementar baseado em BaseScraper

# Inicializar sessÃ£o
if scraper.initialize_session():
    # Definir tokens (obtidos manualmente)
    scraper.set_tokens(session_id="seu_session_id", juris_token="seu_token")
    
    # Processar lista de processos
    processos = ["0001203-03.2018.5.10.0021", "0001204-03.2018.5.10.0021"]
    documents = scraper.process_processo_list(processos)
    
    # Salvar no banco
    for doc in documents:
        processo = ProcessoJudicial.from_dict(doc)
        db.insert_processo(processo)
```

## ğŸ“Š Estrutura do Banco de Dados

### Tabela: processos_judiciais
```sql
CREATE TABLE processos_judiciais (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    numero_processo TEXT NOT NULL,
    numero_processo_planilha TEXT NOT NULL,
    tribunal TEXT,
    classe_processo TEXT,
    tipo_documento TEXT,
    data_julgamento TEXT,
    data_publicacao TEXT,
    relator TEXT,
    partes TEXT,
    link_decisao TEXT,
    conteudo_bruto_decisao TEXT,
    origem_texto TEXT,
    colecao_api TEXT,
    id_documento_api TEXT,
    processado_nlp BOOLEAN DEFAULT FALSE,
    data_coleta TEXT NOT NULL,
    data_processamento TEXT,
    metadados TEXT
);
```

### Tabela: resultados_nlp
```sql
CREATE TABLE resultados_nlp (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    processo_id INTEGER NOT NULL,
    resumo_extrativo TEXT,
    palavras_chave TEXT,
    tema_principal TEXT,
    sentimento TEXT,
    entidades_nomeadas TEXT,
    metadados_nlp TEXT,
    data_processamento TEXT NOT NULL,
    FOREIGN KEY (processo_id) REFERENCES processos_judiciais (id)
);
```

## ğŸ” Sistema de Logging

O sistema utiliza logging estruturado com suporte a:
- Logs em arquivo e console
- Formato JSON para anÃ¡lise
- MÃ©tricas de performance
- Rastreamento de erros
- Contexto de operaÃ§Ãµes

Exemplo de log:
```json
{
    "timestamp": "2024-01-15T10:30:00Z",
    "level": "info",
    "logger": "DatabaseManager",
    "event": "processo_inserted",
    "processo_id": 123,
    "numero_processo": "0001203-03.2018.5.10.0021"
}
```

## ğŸ§ª Testes

```bash
# Executar todos os testes
pytest

# Executar com cobertura
pytest --cov=src/acoes_coletivas

# Executar testes especÃ­ficos
pytest tests/test_database.py
```

## ğŸ“ˆ Monitoramento

### MÃ©tricas DisponÃ­veis

- Total de processos coletados
- Processos processados por NLP
- Taxa de sucesso das coletas
- Tempo de execuÃ§Ã£o das operaÃ§Ãµes
- Erros e exceÃ§Ãµes

### Logs de OperaÃ§Ã£o

Todos os logs sÃ£o armazenados em:
- `logs/acoes_coletivas.log` (arquivo)
- Console (durante execuÃ§Ã£o)
- Banco de dados (tabela `logs_execucao`)

## ğŸ”’ SeguranÃ§a

- Tokens de autenticaÃ§Ã£o nÃ£o sÃ£o armazenados em logs
- ConfiguraÃ§Ãµes sensÃ­veis via variÃ¡veis de ambiente
- ValidaÃ§Ã£o de entrada de dados
- Rate limiting para evitar bloqueios

## ğŸš€ Desenvolvimento

### Adicionando Novos Scrapers

1. Herde de `BaseScraper`
2. Implemente os mÃ©todos abstratos
3. Adicione logging apropriado
4. Inclua testes unitÃ¡rios

```python
from src.acoes_coletivas.scraper.base import BaseScraper, SearchParams, ScrapingResult

class MeuScraper(BaseScraper):
    def initialize_session(self) -> bool:
        # Implementar inicializaÃ§Ã£o
        pass
    
    def search_documents(self, params: SearchParams) -> ScrapingResult:
        # Implementar busca
        pass
    
    def extract_document_content(self, document: dict) -> dict:
        # Implementar extraÃ§Ã£o
        pass
    
    def cleanup(self):
        # Implementar limpeza
        pass
```

### PadrÃµes de CÃ³digo

- Use type hints
- Docstrings para funÃ§Ãµes pÃºblicas
- Logging estruturado
- Tratamento de exceÃ§Ãµes
- Testes unitÃ¡rios

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. FaÃ§a commit das mudanÃ§as
4. Abra um Pull Request

## ğŸ“„ Scripts Legados

Os scripts originais estÃ£o mantidos para referÃªncia:
- `1 - extrair dados selenium.py`
- `1.1 - extrair dados.py`
- `2 - resumo etapa 1.py`
- `3 - resumo_etapa_2.py`
- `4 - Ãºltima etapa.py`

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verifique os logs em `logs/acoes_coletivas.log`
2. Consulte a documentaÃ§Ã£o tÃ©cnica
3. Abra uma issue no repositÃ³rio

## ğŸ—ºï¸ Roadmap

### VersÃ£o 1.1
- [ ] Interface CLI completa
- [ ] Processamento NLP avanÃ§ado
- [ ] ExportaÃ§Ã£o para Excel/PDF
- [ ] RelatÃ³rios automatizados

### VersÃ£o 1.2
- [ ] Interface web
- [ ] Dashboard interativo
- [ ] API REST
- [ ] IntegraÃ§Ã£o com PostgreSQL

### VersÃ£o 2.0
- [ ] Machine Learning para classificaÃ§Ã£o
- [ ] AnÃ¡lise preditiva
- [ ] IntegraÃ§Ã£o com outros sistemas
- [ ] Escalabilidade para grandes volumes

## ğŸ“ Changelog

### v1.0.0 (Atual)
- âœ… Estrutura profissional do projeto
- âœ… Sistema de banco de dados SQLite
- âœ… Logging estruturado
- âœ… ConfiguraÃ§Ã£o centralizada
- âœ… Base para scrapers
- âœ… DocumentaÃ§Ã£o completa

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

**Desenvolvido com ğŸ’™ para automatizar a anÃ¡lise de aÃ§Ãµes coletivas judiciais** 